{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surname Classification Using a Character\n",
    "\n",
    "### Using built-in RNNs: nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary, Vectorizer, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to process text and extract vocabulary for mapping\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx (dict): a pre-existing map of tokens to indices\n",
    "        \"\"\"\n",
    "\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        \"\"\" returns a dictionary that can be serialized \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" instantiates the Vocabulary from a serialized dictionary \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update mapping dicts based on the token.\n",
    "\n",
    "        Args:\n",
    "            token (str): the item to add into the Vocabulary\n",
    "        Returns:\n",
    "            index (int): the integer corresponding to the token\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"Add a list of tokens into the Vocabulary\n",
    "        \n",
    "        Args:\n",
    "            tokens (list): a list of string tokens\n",
    "        Returns:\n",
    "            indices (list): a list of indices corresponding to the tokens\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Return the token associated with the index\n",
    "        \n",
    "        Args: \n",
    "            index (int): the index to look up\n",
    "        Returns:\n",
    "            token (str): the token corresponding to the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the Vocabulary\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Vocabulary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d1d467000763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mSequenceVocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n\u001b[0;32m      3\u001b[0m                  \u001b[0mmask_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"<MASK>\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin_seq_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"<BEGIN>\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  end_seq_token=\"<END>\"):\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Vocabulary' is not defined"
     ]
    }
   ],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\",\n",
    "                 mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",\n",
    "                 end_seq_token=\"<END>\"):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "                         'mask_token': self._mask_token,\n",
    "                         'begin_seq_token': self._begin_seq_token,\n",
    "                         'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Retrieve the index associated with the token \n",
    "          or the UNK index if token isn't present.\n",
    "        \n",
    "        Args:\n",
    "            token (str): the token to look up \n",
    "        Returns:\n",
    "            index (int): the index corresponding to the token\n",
    "        Notes:\n",
    "            `unk_index` needs to be >=0 (having been added into the Vocabulary) \n",
    "              for the UNK functionality \n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameVectorizer(object):\n",
    "    \"\"\" The Vectorizer which coordinates the Vocabularies and puts them to use\"\"\"   \n",
    "    def __init__(self, char_vocab, nationality_vocab):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            char_vocab (Vocabulary): maps characters to integers\n",
    "            nationality_vocab (Vocabulary): maps nationalities to integers\n",
    "        \"\"\"\n",
    "        self.char_vocab = char_vocab\n",
    "        self.nationality_vocab = nationality_vocab\n",
    "\n",
    "    def vectorize(self, surname, vector_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            surname (str): the string of characters\n",
    "            vector_length (int): an argument for forcing the length of index vector\n",
    "        \"\"\"\n",
    "        indices = [self.char_vocab.begin_seq_index]\n",
    "        indices.extend(self.char_vocab.lookup_token(token) \n",
    "                       for token in surname)\n",
    "        indices.append(self.char_vocab.end_seq_index)\n",
    "\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype=np.int64)         \n",
    "        out_vector[:len(indices)] = indices\n",
    "        out_vector[len(indices):] = self.char_vocab.mask_index\n",
    "        \n",
    "        return out_vector, len(indices)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, surname_df):\n",
    "        \"\"\"Instantiate the vectorizer from the dataset dataframe\n",
    "        \n",
    "        Args:\n",
    "            surname_df (pandas.DataFrame): the surnames dataset\n",
    "        Returns:\n",
    "            an instance of the SurnameVectorizer\n",
    "        \"\"\"\n",
    "        char_vocab = SequenceVocabulary()\n",
    "        nationality_vocab = Vocabulary()\n",
    "\n",
    "        for index, row in surname_df.iterrows():\n",
    "            for char in row.surname:\n",
    "                char_vocab.add_token(char)\n",
    "            nationality_vocab.add_token(row.nationality)\n",
    "\n",
    "        return cls(char_vocab, nationality_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        char_vocab = SequenceVocabulary.from_serializable(contents['char_vocab'])\n",
    "        nat_vocab =  Vocabulary.from_serializable(contents['nationality_vocab'])\n",
    "\n",
    "        return cls(char_vocab=char_vocab, nationality_vocab=nat_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'char_vocab': self.char_vocab.to_serializable(), \n",
    "                'nationality_vocab': self.nationality_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e61d2de2656e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mSurnameDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurname_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \"\"\"\n\u001b[0;32m      4\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0msurname_df\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, surname_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            surname_df (pandas.DataFrame): the dataset\n",
    "            vectorizer (SurnameVectorizer): vectorizer instatiated from dataset\n",
    "        \"\"\"\n",
    "        self.review_df = review_df \n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        self._max_seq_length = max(map(len, self.surname_df.surname)) + 2   # add 2 for begin_seq_token and end_seq_token\n",
    "\n",
    "        self.train_df = self.review_df[self.surname_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.surname_df[self.surname_df.split=='val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.surname_df[self.surname_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size), \n",
    "                             'val': (self.val_df, self.validation_size), \n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "\n",
    "        self.set_split('train')\n",
    "        \n",
    "        # Class weights\n",
    "        class_counts = self.train_df.nationality.value_counts().to_dict()\n",
    "        def sort_key(item):\n",
    "            return self._vectorizer.nationality_vocab.lookup_token(item[0])\n",
    "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
    "        frequencies = [count for _, count in sorted_counts]\n",
    "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, surname_csv):\n",
    "        \"\"\"Load dataset and make a new vectorizer from scratch\n",
    "        \n",
    "        Args:\n",
    "            surname_csv (str): location of the dataset\n",
    "        Returns:\n",
    "            an instance of SurnameDataset\n",
    "        \"\"\"\n",
    "        surname_df = pd.read_csv(surname_csv)\n",
    "        train_surname_df = surname_df[surname_df.split=='train']\n",
    "        return cls(surname_df, SurnameVectorizer.from_dataframe(train_surname_df))\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, surname_csv, vectorizer_filepath):\n",
    "        \"\"\"Load dataset and the corresponding vectorizer. \n",
    "        Used in the case in the vectorizer has been cached for re-use\n",
    "        \n",
    "        Args:\n",
    "            surname_csv (str): location of the dataset\n",
    "            vectorizer_filepath (str): location of the saved vectorizer\n",
    "        Returns:\n",
    "            an instance of SurnameDataset\n",
    "        \"\"\"\n",
    "        review_df = pd.read_csv(review_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(surname_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"a static method for loading the vectorizer from file\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location of the serialized vectorizer\n",
    "        Returns:\n",
    "            an instance of SurnameVectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        \"\"\"saves the vectorizer to disk using json\n",
    "        \n",
    "        Args:\n",
    "            vectorizer_filepath (str): the location to save the vectorizer\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" returns the vectorizer \"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"the primary entry point method for PyTorch datasets\n",
    "        \n",
    "        Args:\n",
    "            index (int): the index to the data point \n",
    "        Returns:\n",
    "            a dictionary holding the data point's:\n",
    "                features (x_data)\n",
    "                label (y_target)\n",
    "                feature length (x_length)\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        surname_vector, vec_length = \\\n",
    "            self._vectorizer.vectorize(row.surname, self._max_seq_length)\n",
    "        \n",
    "        nationality_index = \\\n",
    "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
    "\n",
    "        return {'x_data': surname_vector, \n",
    "                'y_target': nationality_index, \n",
    "                'x_length': vec_length}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "\n",
    "    \n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"\n",
    "    A generator function which wraps the PyTorch DataLoader. It will \n",
    "      ensure each tensor is on the write device location.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def column_gather(y_out, x_lengths):\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        out.append(y_out[batch_index, column_index])\n",
    "\n",
    "    return torch.stack(out)\n",
    "\n",
    "\n",
    "## Building Surname Classifier Using Built-in RNN:\n",
    "class SurnameClassifier(nn.Module):\n",
    "    \"\"\" A Classifier with an RNN to extract features and an MLP to classify \"\"\"\n",
    "    def __init__(self, embedding_size, num_embeddings, num_classes,\n",
    "                 rnn_hidden_size, bidirectional=True, batch_first=True, padding_idx=0):\n",
    "        super(SurnameClassifier, self).__init__()\n",
    "\n",
    "        if bidirectional == False:\n",
    "             self.num_directions = 1\n",
    "        else:\n",
    "             self.num_directions = 2\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings=num_embeddings,\n",
    "                                embedding_dim=embedding_size,\n",
    "                                padding_idx=padding_idx)\n",
    "        \n",
    "        ## Built in RNN function as nn.RNN\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=embedding_size,\n",
    "                             hidden_size=rnn_hidden_size,\n",
    "                             batch_first=batch_first, \n",
    "                             num_layers = 2,\n",
    "                             dropout = 0.4)\n",
    "       \n",
    "        self.fc1 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,\n",
    "                         out_features=rnn_hidden_size*self.num_directions)\n",
    "        self.fc2 = nn.Linear(in_features=rnn_hidden_size*self.num_directions,\n",
    "                          out_features=num_classes)\n",
    "        # for batch norm\n",
    "        self.bn1 = nn.BatchNorm1d(rnn_hidden_size*self.num_directions) \n",
    "\n",
    "\n",
    "    def forward(self, x_in, x_lengths=None, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier \"\"\"\n",
    "        x_embedded = self.emb(x_in)\n",
    "        \n",
    "        y_out, _ = self.rnn(x_embedded)  # x_embedded: (batch, seq_size, feat_size); y_out: (batch, seq_size, hidden_size)\n",
    "\n",
    "        #y_out = y_out_last.squeeze(dim=0)  # convert (1, batch, hidden_size) to (batch, hidden_size)\n",
    "        \n",
    "        if x_lengths is not None:\n",
    "             y_out = column_gather(y_out, x_lengths)   # y_out gets the last hidden vector of each input: (batch, hidden_size)\n",
    "        else:\n",
    "             y_out = y_out[:, -1, :]\n",
    "            \n",
    "        # with batch norm and dropout\n",
    "        #y_out = F.relu(self.bn1(self.fc1(F.dropout(y_out, 0.2, training=self.training))))\n",
    "        \n",
    "        # with  only dropout\n",
    "        y_out = self.fc2(F.dropout(y_out, 0.2, training=self.training))          # y_out: (batch, num_classes)\n",
    "       \n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=1)\n",
    "            \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    surname_csv=\"data/surnames/surnames_with_splits.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/ch6/surname_classification\",\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=100,\n",
    "    rnn_hidden_size=64,\n",
    "    bidirectional=False,\n",
    "    #bidirectional=True,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=64,\n",
    "    #num_epochs=200,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=64,\n",
    "    seed=1337,\n",
    "    early_stopping_criteria=5,\n",
    "    # Runtime hyper parameter\n",
    "    cuda=True,\n",
    "    catch_keyboard_interrupt=True,\n",
    "    reload_from_files=False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "    \n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir,\n",
    "                                        args.vectorizer_file)\n",
    "\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "if args.reload_from_files and os.path.exists(args.vectorizer_file):\n",
    "    # training from a checkpoint\n",
    "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv, \n",
    "                                                              args.vectorizer_file)\n",
    "else:\n",
    "    # create dataset and vectorizer\n",
    "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "classifier = SurnameClassifier(embedding_size=args.char_embedding_size, \n",
    "                               num_embeddings=len(vectorizer.char_vocab),\n",
    "                               num_classes=len(vectorizer.nationality_vocab),\n",
    "                               rnn_hidden_size=args.rnn_hidden_size,\n",
    "                               padding_idx=vectorizer.char_vocab.mask_index,\n",
    "                               bidirectional=args.bidirectional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07357b6c2397431fbacf17d1219a2980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', max=64.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485bbf38520e4f6484fef6b939d214d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=120.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ea288a5130407ab7f0b1f10f36d709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=25.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strt time## 16:11:39\n",
      "strt time## 16:23:05\n"
     ]
    }
   ],
   "source": [
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "    \n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                           mode='min', factor=0.5,\n",
    "                                           patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc='training routine', total=args.num_epochs, position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='split=train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='split=val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "t = time.localtime()\n",
    "start_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(\"strt time##\",start_time)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0, set train mode on\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------    \n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # step 2. compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    \n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, \n",
    "                                           batch_size=args.batch_size, \n",
    "                                           device=args.device)\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # compute the output\n",
    "            y_pred = classifier(x_in=batch_dict['x_data'], \n",
    "                                x_lengths=batch_dict['x_length'])\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            running_loss += (loss.item() - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")\n",
    "t1 = time.localtime()\n",
    "start_time = time.strftime(\"%H:%M:%S\", t1)\n",
    "print(\"strt time##\",start_time)\n",
    "\n",
    "## the Time taken is always less than 14 min which is least time taken model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = train_state['train_acc']\n",
    "val_acc = train_state['val_acc']\n",
    "loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## The below graph shows that after a certain point, both the loss(Training and Validation) become stabilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## The below graph indicates, that accuracy increases alot and stabilizes after certain point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "dataset.class_weights = dataset.class_weights.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "y_pred_list = []         # store predicted values for confusion matrix\n",
    "y_nationality_list = []  # ground truth value\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # compute the output\n",
    "    y_pred =  classifier(batch_dict['x_data'],\n",
    "                         x_lengths=batch_dict['x_length'])\n",
    "\n",
    "    # store predicted values and ground truth values for calculating confusion matrix\n",
    "    y_pred_list.extend(y_pred.max(dim=1)[1].cpu().numpy())\n",
    "    y_nationality_list.extend(batch_dict['y_target'].cpu().numpy())\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4509895753860473;\n",
      "Test Accuracy: 54.1875\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {};\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {}\".format(train_state['test_acc']))\n",
    "\n",
    "## The below indicates thhe test loss; and it varied between(1.3-14 with an accuracy of 54-56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "nationality_classes = []\n",
    "for i in range(len(dataset._vectorizer.nationality_vocab)):\n",
    "    nationality_classes.append(dataset._vectorizer.nationality_vocab.lookup_index(i))\n",
    "print(nationality_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True        Arabic  Chinese  Czech  Dutch  English  French  German  Greek  \\\n",
      "Predicted                                                                   \n",
      "Arabic         219        0      1      1       20       1       2      0   \n",
      "Chinese          0       17      0      0        7       0       1      0   \n",
      "Czech            0        0     14      0       15       0       6      0   \n",
      "Dutch            0        0      3     18       38       1      15      0   \n",
      "English          0        0      2      1       73       2       4      0   \n",
      "French           5        0      2      5       63      18       4      0   \n",
      "German           0        1      8      5       53       3      44      0   \n",
      "Greek            0        0      0      0        6       0       0     21   \n",
      "Irish            0        0      0      2       44       5       2      0   \n",
      "Italian          3        0      2      0        3       0       0      0   \n",
      "Japanese         0        0      3      0        3       0       1      1   \n",
      "Korean           2        8      0      1        3       0       0      0   \n",
      "Polish           0        0     10      0        2       0       0      0   \n",
      "Portuguese       3        0      2      0        6       1       0      1   \n",
      "Russian          0        1      8      0        8       2       1      0   \n",
      "Scottish         0        0      3      2       77       2       2      0   \n",
      "Spanish          0        0      3      1        8       0       1      0   \n",
      "Vietnamese       2        5      0      0        1       0       0      0   \n",
      "\n",
      "True        Irish  Italian  Japanese  Korean  Polish  Portuguese  Russian  \\\n",
      "Predicted                                                                   \n",
      "Arabic          0        0         8       1       0           1        3   \n",
      "Chinese         0        0         2       2       0           0        1   \n",
      "Czech           1        1         0       0       1           0        6   \n",
      "Dutch           0        0         0       0       1           0        8   \n",
      "English         2        0         0       0       0           1        2   \n",
      "French          1        4         2       1       0           0        7   \n",
      "German          5        1         0       0       1           0       16   \n",
      "Greek           0        1         1       0       0           1        6   \n",
      "Irish          15        1         0       0       0           0        9   \n",
      "Italian         1       61         9       0       0           1        5   \n",
      "Japanese        0        1        87       0       0           0        6   \n",
      "Korean          0        0         1       6       0           0        2   \n",
      "Polish          0        0         0       0       7           0       15   \n",
      "Portuguese      0        6         1       1       0           2        3   \n",
      "Russian         1        0         1       0       2           0      247   \n",
      "Scottish        0        2         0       1       1           0        1   \n",
      "Spanish         0       10         1       0       2           3        3   \n",
      "Vietnamese      0        0         1       1       0           0        3   \n",
      "\n",
      "True        Scottish  Spanish  Vietnamese  \n",
      "Predicted                                  \n",
      "Arabic             0        0           0  \n",
      "Chinese            1        0           2  \n",
      "Czech              1        2           0  \n",
      "Dutch              1        1           0  \n",
      "English            1        0           0  \n",
      "French             1        1           0  \n",
      "German             0        1           0  \n",
      "Greek              0        2           0  \n",
      "Irish              0        2           1  \n",
      "Italian            0        5           1  \n",
      "Japanese           0        1           0  \n",
      "Korean             0        0           3  \n",
      "Polish             0        0           0  \n",
      "Portuguese         0        8           0  \n",
      "Russian            1        0           0  \n",
      "Scottish           4        0           0  \n",
      "Spanish            0       15           0  \n",
      "Vietnamese         0        0           3  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cm = confusion_matrix(y_nationality_list, y_pred_list)\n",
    "cm_df = pd.DataFrame(cm.T, index=nationality_classes, columns=nationality_classes)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       234\n",
      "           1       0.52      0.53      0.52        32\n",
      "           2       0.30      0.23      0.26        61\n",
      "           3       0.21      0.50      0.30        36\n",
      "           4       0.83      0.17      0.28       430\n",
      "           5       0.16      0.51      0.24        35\n",
      "           6       0.32      0.53      0.40        83\n",
      "           7       0.55      0.91      0.69        23\n",
      "           8       0.19      0.58      0.28        26\n",
      "           9       0.67      0.69      0.68        88\n",
      "          10       0.84      0.76      0.80       114\n",
      "          11       0.23      0.46      0.31        13\n",
      "          12       0.21      0.47      0.29        15\n",
      "          13       0.06      0.22      0.09         9\n",
      "          14       0.91      0.72      0.80       343\n",
      "          15       0.04      0.40      0.08        10\n",
      "          16       0.32      0.39      0.35        38\n",
      "          17       0.19      0.30      0.23        10\n",
      "\n",
      "    accuracy                           0.54      1600\n",
      "   macro avg       0.41      0.52      0.42      1600\n",
      "weighted avg       0.71      0.54      0.56      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_nationality_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nationality(surname, classifier, vectorizer):\n",
    "    vectorized_surname, vec_length = vectorizer.vectorize(surname)\n",
    "    vectorized_surname = torch.tensor(vectorized_surname).unsqueeze(dim=0)\n",
    "    vec_length = torch.tensor([vec_length], dtype=torch.int64)\n",
    "    \n",
    "    result = classifier(vectorized_surname, vec_length, apply_softmax=True)\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    \n",
    "    index = indices.item()\n",
    "    prob_value = probability_values.item()\n",
    "\n",
    "    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
    "\n",
    "    return {'nationality': predicted_nationality, 'probability': prob_value, 'surname': surname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nationality': 'Irish', 'probability': 0.8669715523719788, 'surname': 'McMahan'}\n",
      "{'nationality': 'Japanese', 'probability': 0.9770126342773438, 'surname': 'Nakamoto'}\n",
      "{'nationality': 'Chinese', 'probability': 0.723421037197113, 'surname': 'Wan'}\n",
      "{'nationality': 'Korean', 'probability': 0.8201289772987366, 'surname': 'Cho'}\n",
      "{'nationality': 'Polish', 'probability': 0.7514048218727112, 'surname': 'Lebzak'}\n",
      "{'nationality': 'Japanese', 'probability': 0.3204655051231384, 'surname': 'Obinata'}\n",
      "{'nationality': 'Italian', 'probability': 0.8872742056846619, 'surname': 'Acconci'}\n",
      "{'nationality': 'Russian', 'probability': 0.9738385081291199, 'surname': 'Chekhoev'}\n"
     ]
    }
   ],
   "source": [
    "#surname = input(\"Enter a surname: \")\n",
    "classifier = classifier.to(\"cpu\")\n",
    "for surname in ['McMahan', 'Nakamoto', 'Wan', 'Cho','Lebzak','Obinata','Acconci','Chekhoev']:\n",
    "    print(predict_nationality(surname, classifier, vectorizer))\n",
    "\n",
    "## Here I have included a large sum of data to show case that the 'probability' of finding 'nationality' is high for all surnames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences Made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE 1 : The Best Model\n",
    "## HyperParameters USed:\n",
    "1. Learning Rate - 1e-3\n",
    "2. Drop Out - 0.4\n",
    "3. Batch Norm - No\n",
    "4. Hidden Dimension - 64\n",
    "5. Input Layers - 2\n",
    "6. RNN parameter - nn.RNN\n",
    "7. Batch Size - 64\n",
    "8. Total Time to train - 14min\n",
    "9. Test Loss - 1.4\n",
    "10. Test Accuracy - (54-56)\n",
    "The above model will be the best suited Model among using nn.RNN due to following reasons:\n",
    "    - Time Take is less and accuracy is more. On little more training, the accuracy was averagely around 56 and the test loss is \n",
    "    very less(nearly to 1.3-1.4) making the model more stable.\n",
    "###\n",
    "CASE 2:\n",
    "# Another Best Model is also obtained with nn.RNN with Hyper parameters as:\n",
    "1. Learning Rate - 1e-3\n",
    "2. Drop Out - 0.4\n",
    "3. Batch Norm - No\n",
    "4. Hidden Dimension - 64\n",
    "5. Input Layers - 2\n",
    "6. RNN parameter - nn.RNN\n",
    "7. Batch size  - 32 \n",
    "8. Time taken - 19 min\n",
    "9. Test Loss - 1.4\n",
    "10. Test Accuracy - (56 - 60)\n",
    "    - Accuracy is much higher than the first case but the taken taken is little more than Case 1.\n",
    "    \n",
    "CASE 3:    \n",
    "## Inferences from nn.GRU & nn.LSTM:\n",
    "For nn.LSTM and Model nn.GRU:\n",
    "    -  Time Taken exceeded more than 40 min when the batch size/Hidden Dim.\n",
    "    -  Test Accuracy Rate is very low comparing with nn.RNN Model with same paramaters.\n",
    "    -  Test Accuracy loss was constantly above 2.0, which makes nn.RNN #The Best Model.\n",
    "    - (Have Attached the Excel, that contains the accuracy and probability values on different combination on hyper Parameters\n",
    "      and other built-in RNNs.)\n",
    "                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
